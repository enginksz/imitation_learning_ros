# @package _global_

training:
  start: 10000
  batch_size: 128
  learning_rate: 0.000255937368851155
reinforcement:
  discount: 0.985100239738822
  target_temperature: -0.5119041716679931
  polyak_factor: 0.9886118377372622
imitation:
  trajectories: 5
  discriminator:
    hidden_size: 128
    depth: 2
    activation: relu
    input_dropout: 0.07764808554202318
    dropout: 0.37710048034787175
  pretraining:
    iterations: 39187
  learning_rate: 0.00020942082071676846
  weight_decay: 0.7388725411146879
